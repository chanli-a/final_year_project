{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb227302",
   "metadata": {},
   "source": [
    "Run time for some previous code was far too long (600+ minutes). Try to optimise code in this file to reduce run time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121d308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github temp.jl, converted to python\n",
    "\n",
    "# this section is about incorporating temperature dependence \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "rng = default_rng(111) # random number generator \n",
    "\n",
    "\n",
    "# note that the u(T) and m(T) equation have the same structure, except the parameters are different. \n",
    "# both of the equations involve parameters like:\n",
    "# B0 (base rate), E (activation energy), k (Boltzmann constant), Ed (deactivation energy), Tp (peak performance temperature), and Tr (reference temperature) \n",
    "# first, we want to generate random parameters for each consumer (as mentioned above), like B, E, Tp\n",
    "# and for each of these temp-dependent parameters, we want to generate one for uptake u(T) and one for respiration m(T) \n",
    "# they're not actually fully random, as we do define mean and variance for teh parameters, and draw from a multivariate normal distribution \n",
    "\n",
    "\n",
    "\n",
    "def randtemp_param(N, kw):\n",
    "    \"\"\"\n",
    "    Generate random temperature-dependent trait parameters for consumers.\n",
    "    \n",
    "    Returns:\n",
    "        B: base rates (N x 2)\n",
    "        E: activation energies (N x 2)\n",
    "        Tp: peak temperatures (N x 2)\n",
    "    \"\"\"\n",
    "    L = kw['L'] # leakage \n",
    "    rho_t = kw['rho_t']\n",
    "\n",
    "    L_v = np.mean(L)\n",
    "    B0_m = -1.4954 # I think this is mortality / respiration rate \n",
    "    B0_CUE = 0.1953 \n",
    "    B0_u = np.log(np.exp(B0_m) / (1 - L_v - B0_CUE)) # I think this is uptake rate. dependent on carbon use efficiency (CUE) and leakage rate\n",
    "    \n",
    "    B0 = np.array([B0_u, B0_m]) # B0 is a vector of base rates for uptake and respiration\n",
    "    B0_var = 0.17 * np.abs(B0) # variance of base rates, 0.17 is a scaling factor\n",
    "    E_mean = np.array([0.8146, 0.5741]) # mean activation energies for uptake and respiration\n",
    "    E_var = 0.1364 * E_mean # variance of activation energies, 0.1364 is a scaling factor\n",
    "    cov_xy = rho_t * np.sqrt(B0_var * E_var) # covariance between base rates and activation energies, rho_t is the correlation coefficient\n",
    "\n",
    "    cov_u = np.array([[B0_var[0], cov_xy[0]], [cov_xy[0], E_var[0]]]) # covariance matrix for uptake\n",
    "    cov_m = np.array([[B0_var[1], cov_xy[1]], [cov_xy[1], E_var[1]]]) # covariance matrix for respiration\n",
    "\n",
    "    allu = multivariate_normal.rvs(mean=[B0[0], E_mean[0]], cov=cov_u, size=N).T # draw random samples from multivariate normal distribution for uptake\n",
    "    allm = multivariate_normal.rvs(mean=[B0[1], E_mean[1]], cov=cov_m, size=N).T # draw random samples from multivariate normal distribution for respiration\n",
    "\n",
    "    B = np.column_stack((np.exp(allu[0]), np.exp(allm[0]))) # exponentiate the base rates to get the actual values\n",
    "    E = np.column_stack((allu[1], allm[1])) # activation energies are already in the correct form\n",
    "\n",
    "    Tpu = 273.15 + rng.normal(35, 5, N) # draw random peak temperatures for uptake from a normal distribution with mean 35 and std 5\n",
    "    Tpm = Tpu + 3 # peak temperature for respiration is 3 degrees higher than for uptake\n",
    "    Tp = np.column_stack((Tpu, Tpm)) # combine the peak temperatures into a single array \n",
    "\n",
    "    return B, E, Tp\n",
    "\n",
    "\n",
    "# randtemp_param_test = randtemp_param(3, {'L': 0.4, 'rho_t': -0.75}) \n",
    "# print(randtemp_param_test) \n",
    "# this works - produces 2D arrays \n",
    "\n",
    "\n",
    "# now we have generated parameters (generating B, E, Tp) for each consumer \n",
    "# we did this by drawing from a multivariate normal distribution, with some constraints like mean, variance, correlation that we defined \n",
    "# now that the parameters are generated, we can incorporate them into the Arrhenius equation to calculate the temperature-dependent trait values \n",
    "# since uptake u(T) and respiration m(T) both depend on these parameters like B, E, Tp (which we have now defined) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def temp_trait(N, kw):\n",
    "    \"\"\"\n",
    "    Compute temperature-dependent trait scaling based on an Arrhenius-like thermal performance curve.\n",
    "    \n",
    "    Arguments:\n",
    "        N: number of consumers\n",
    "        kw: dict containing temperature parameters (T, Tr, Ed, L, rho_t)\n",
    "\n",
    "    Returns:\n",
    "        temp_p: temperature-scaled trait values (vector of size N)\n",
    "        B, E: base rates and activation energies (N x 2)\n",
    "        Tp: peak temperatures for uptake and respiration (N x 2)\n",
    "    \"\"\"\n",
    "    k = 0.0000862  # Boltzmann constant. used in exponential term of the Arrhenius equation\n",
    "    T = kw['T']\n",
    "    Tr = kw['Tr'] \n",
    "    Ed = kw['Ed']\n",
    "\n",
    "    B, E, Tp = randtemp_param(N, kw) # draw random base rates (B), activation energies (E), and peak temperatures (Tp) for each consumer. \n",
    "    # we are using the previously defined function to generate these parameters  \n",
    "\n",
    "    # Arrhenius function with high-temp deactivation\n",
    "\n",
    "    # uptake rate u(T)\n",
    "    temp_p_u = B[:, 0] * np.exp((-E[:, 0] / k) * ((1 / T) - (1 / Tr))) / \\\n",
    "              (1 + (E[:, 0] / (Ed - E[:, 0])) * np.exp(Ed / k * (1 / Tp[:, 0] - 1 / T)))\n",
    "    \n",
    "    # respiration rate m(T) \n",
    "    temp_p_m = B[:, 1] * np.exp((-E[:, 1] / k) * ((1 / T) - (1 / Tr))) / \\\n",
    "              (1 + (E[:, 1] / (Ed - E[:, 1])) * np.exp(Ed / k * (1 / Tp[:, 1] - 1 / T)))\n",
    "\n",
    "    temp_p = np.column_stack((temp_p_u, temp_p_m))  # shape (N,2)\n",
    "    \n",
    "    return temp_p, B, E, Tp\n",
    "\n",
    "\n",
    "# temp_trait_test = temp_trait(3, {'T': 273.15 + 10, 'Tr': 273.15 + 10, 'Ed': 3.5, 'L': 0.4, 'rho_t': -0.75})\n",
    "# print(temp_trait_test)\n",
    "\n",
    "\n",
    "# this temp_trait function uses the previous randtemp_param function to generate parameters for TPC, which are B, E, Tp \n",
    "# and then it uses these parameters to calculate the temperature-dependent trait values (u and m, which are uptake and respiration)  \n",
    "# it does this by putting these parameters into the Arrhenius-like TPC equations u(T) and m(T) \n",
    "# the inputs are N (number of consumers) and kw (a dictionary of parameters like T, Tr, Ed, L, rho_t)\n",
    "# and the outputs are the temp_p (temperature-scaled trait values), B (base rates), E (activation energies), and Tp (peak temperatures)\n",
    "# we could define some temperature T, and the temp_p functions would calculate the resulting u and m for that temperature \n",
    "# so using this, we can compare e.g. low vs high temperatures by defining different T values \n",
    "# and potentially make continuous graphs of temperature vs growth rate or something, and use that to inform timescale separation / GLV accuracy \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42b142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github micrm_params.jl, converted to python \n",
    "\n",
    "# in the previous block of code, we generated temperature-dependent parameters\n",
    "# but those parameters were just for the TPC \n",
    "# we also need to produce the other parameters for MiCRM \n",
    "# so this block of code focuses on defining parameters for MiCRM \n",
    "# and we later use these parameters to run simulations etc \n",
    "\n",
    "\n",
    "# kw is a dictionary carrying all the model inputs and intermediate results (temp, TPC scaling, leakage scalar, etc) \n",
    "# we like to include it (like in def_m) even though it's not needed for the default version\n",
    "# so that any generator function can just pull out what it needs from kw \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Default parameter-generating functions\n",
    "def def_m(N, M, kw):\n",
    "    # Respiration (mortality) rates: ones vector of length N.\n",
    "    return np.ones(N)\n",
    "\n",
    "def def_rho(N, M, kw):\n",
    "    # Resource-specific supply rates: ones vector of length M.\n",
    "    # this was originally resource loss rate, but i changed it to supply so it makes sense with the equation \n",
    "    return np.ones(M)\n",
    "\n",
    "def def_omega(N, M, kw):\n",
    "    # Resource loss rates: ones vector of length M.\n",
    "    return np.ones(M)\n",
    "\n",
    "\n",
    "# the above code for def_m and def_rho are just returning vectors of ones, length N for respiration (m) and length M for supply (rho). \n",
    "# these are like the 'default' respiration/mortality rates, and default resource supply rates. def = default \n",
    "# depends on number of consumers N and number of resources M \n",
    "# later we can add temperature dependence, using functions we defined in previous section of code \n",
    "\n",
    "\n",
    "\n",
    "def def_u(N, M, kw):\n",
    "    # Uptake matrix: each of N rows is drawn from a symmetric Dirichlet of dimension M.\n",
    "    # this establishes the structure of the uptake function - it's a matrix of N x M \n",
    "    # unlike others like respiration (m) which is just a vector of length N \n",
    "    # numpy.random.dirichlet uses concentration parameters of length M\n",
    "    return np.random.dirichlet(alpha=np.ones(M), size=N)\n",
    "\n",
    "\n",
    "# the 'u' is an N x M matrix. each of the rows are sampled from a Dirichlet distribution. \n",
    "# each consumer is a row, and each resource is a column. \n",
    "# each consumer's uptake across resources (sum of a row) is 1. but this is randomly allocated among M resources. \n",
    "# so i guess the uptake is not absolute units but it's relative to other resources? \n",
    "# also i think this describes uptake preference (so how much of a certain resource it uptakes vs another one, relatively), not uptake rate which can be temp-dependent (as previously defined) \n",
    "\n",
    "\n",
    "def def_l(N, M, L):\n",
    "    # Leakage-transformation tensor: shape (N, M, M). For each consumer i and resource alpha,\n",
    "    # draw an M-vector from Dirichlet and scale by L[i].\n",
    "    l = np.zeros((N, M, M))\n",
    "    phi = np.ones(M)\n",
    "    for i in range(N):\n",
    "        for alpha in range(M):\n",
    "            draw = np.random.dirichlet(alpha=phi)\n",
    "            l[i, alpha, :] = draw * L[i]\n",
    "    return l\n",
    "\n",
    "# again, i think leakage is relative units (arbitrary units or sth)\n",
    "# more about the 'preference' in terms of which resources are leaked \n",
    "\n",
    "\n",
    "# this is the N x M x M leakage tensor. for each consumer i and resource index alpha, we are drawing an M-vector from a Dirichlet distribution, and scaling it by L[i].\n",
    "# this is the leakage matrix for each consumer-resource pair. \n",
    "# from the paper: \n",
    "# L encodes each strain's metabolic network. L is the leakage-transformation tensor. L determines how consumed substrates are leaked / metabolically transformed \n",
    "# so i think for each strain N + each resource M, there is a whole vector (length M) of what resources that this one coudl be leaked as or transformed into. \n",
    "\n",
    "# these previous functions are 'default' functions for generating parameters\n",
    "# they create simple placeholder values like vectors of 1s, or random Dirichlet distributions \n",
    "# these functions can be overridden (e.g. after we add temp dependence)\n",
    "\n",
    "# next, in generate_params, we will add temperature dependence to the parameters \n",
    "\n",
    "def generate_params(N,\n",
    "                     M,\n",
    "                     f_m=def_m,\n",
    "                     f_rho=def_rho,\n",
    "                     f_omega=def_omega,\n",
    "                     f_u=def_u,\n",
    "                     f_l=def_l,\n",
    "                     **kwargs):\n",
    "    \n",
    "    # f_m = def_m means that if we don't provide a function for f_m, it will use the default one (def_m)\n",
    "    # this is why we had to define the default functions earlier \n",
    "    # **kwargs is any other keyword arguments (not directly specified as function inputs here, but bundled together in dictionary)\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate temperature-dependent MiCRM parameters.\n",
    "\n",
    "    Parameters:\n",
    "        N, M       : integers, number of consumers and resources\n",
    "        f_m, f_rho, f_omega, f_u, f_l : functions to generate m, rho, omega, u, l\n",
    "        kwargs     : other keyword arguments (e.g., T, rho_t, Tr, Ed, L)\n",
    "\n",
    "    Returns:\n",
    "        params : dict with keys 'N', 'M', 'u', 'm', 'l', 'rho', 'omega', 'lambda',\n",
    "                 plus temperature traits and any extra kwargs\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy kwargs for internal use\n",
    "    kw = dict(kwargs)\n",
    "\n",
    "    # Temperature-dependent traits, as defined in previous code block \n",
    "    tt, B, E, Tp = temp_trait(N, kw) # according to previously defined temp_trait function \n",
    "    # tt is the first output of the temp_trait function, which is temp_p\n",
    "\n",
    "    \n",
    "    kw['tt'] = tt\n",
    "   \n",
    "    # in this section above:\n",
    "    # we plug in N and kw (kw is a dictionary of parameters), both of which are inputs to the overall generate_params function\n",
    "    # and using a previously defined function temp_trait, we get parameters for temperature dependence\n",
    "    # the parameters generated include temp_p_u and temp_p_m \n",
    "    # now that we've generated temp_p_u and temp_p_m, we want to store them into kw dictionary \n",
    "\n",
    "    # Generate consumer parameters\n",
    "    m = f_m(N, M, kw) # Respiration (mortality) rates\n",
    "    u = f_u(N, M, kw) # Uptake matrix\n",
    "\n",
    "    # this section above:\n",
    "    # f_m and f_u generate the final parameters for uptake and mortality \n",
    "    # we haven't defined a custom function for f_m or f_u, so it will use the default ones we defined earlier\n",
    "    # so here, it's basically same as m = def_m(N, M, kw) and u = def_u(N, M, kw)\n",
    "\n",
    "\n",
    "    # Leakage-transformation tensor\n",
    "    L = kw.get('L')         # Expect L in kwargs\n",
    "    l = f_l(N, M, L)      # Leakage-transformation \n",
    "\n",
    "    # Total leakage per consumer-resource pair\n",
    "    lambda_ = np.sum(l, axis=2)  # shape (N, M)\n",
    "\n",
    "    # Resource parameters\n",
    "    rho = f_rho(N, M, kw) \n",
    "    omega = f_omega(N, M, kw)\n",
    "\n",
    "    # Assemble base parameter dict\n",
    "    params = {\n",
    "        'N': N,\n",
    "        'M': M,\n",
    "        'u': u,\n",
    "        'm': m,\n",
    "        'l': l,\n",
    "        'rho': rho,\n",
    "        'omega': omega,\n",
    "        'lambda': lambda_,\n",
    "        'L': L,\n",
    "        'B': B,\n",
    "        'E': E,\n",
    "        'Tp': Tp,\n",
    "        'tt': tt\n",
    "    }\n",
    "    # Merge in any extra user-supplied kwargs\n",
    "    params.update(kwargs) \n",
    "\n",
    "    return params # so it shows the base parameter dictionary we defined within this function \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test generate_params just to show how it works:\n",
    "# given N, M, and other parameters like temperature, it generates parameters for MiCRM \n",
    "# and there is an element of stochasticity, because the community assemblies are random \n",
    "\n",
    "# params = generate_params(\n",
    "#     N=10,\n",
    "#     M=5,\n",
    "#     T=310,\n",
    "#     Tr=275,\n",
    "#     Ed=2,\n",
    "#     L=np.random.uniform(0.1, 0.5, size=N),\n",
    "#     rho_t=1\n",
    "# )\n",
    "\n",
    "# print (params)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cba08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github dx_v2.jl, converted to python\n",
    "\n",
    "\n",
    "# now that we've generated parameters, we can write the actual MiCRM model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def growth_MiCRM(dx, x, p, t, i):\n",
    "    \"\"\"\n",
    "    Per-consumer growth contribution for the MiCRM system.\n",
    "    \n",
    "    dx : array of length N+M (mutated in-place)\n",
    "    x  : current state vector [consumers (N), resources (M)]\n",
    "    p  : parameter dict with keys 'm', 'u', 'l', 'N', 'M'\n",
    "    t  : time (unused here)\n",
    "    i  : index of the consumer species to update\n",
    "    \"\"\"\n",
    "    # maintenance loss\n",
    "    dx[i] = -x[i] * p['m'][i]  \n",
    "    # uptake and leakage contributions\n",
    "    for alpha in range(p['M']):\n",
    "        resource_idx = p['N'] + alpha # index of the resource in the state vector, since dx is an array of length N+M\n",
    "        uptake = x[resource_idx] * x[i] * p['u'][i, alpha]\n",
    "        dx[i] += uptake\n",
    "        # subtract leaked fraction\n",
    "        for beta in range(p['M']):\n",
    "            dx[i] -= x[i] * x[resource_idx] * p['u'][i, alpha] * p['l'][i, alpha, beta]\n",
    "\n",
    "\n",
    "\n",
    "def supply_MiCRM(dx, x, p, t, alpha):\n",
    "    \"\"\"\n",
    "    Supply (inflow minus outflow) for resource pools.\n",
    "    \n",
    "    dx : array of length N+M (mutated in-place)\n",
    "    x  : current state vector\n",
    "    p  : parameter dict with keys 'rho', 'omega', 'N', 'M'\n",
    "    t  : time (unused)\n",
    "    alpha : index of the resource pool to update\n",
    "    \"\"\"\n",
    "    idx = p['N'] + alpha\n",
    "    dx[idx] = p['rho'][alpha] - x[idx] * p['omega'][alpha]\n",
    "\n",
    "    # slightly confusing - previously omega was labelled supply and rho the decay \n",
    "    # but was probably a typo \n",
    "    # have fixed previous code and included omega again\n",
    "    # where rho is supply, and omega is decay \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def depletion_MiCRM(dx, x, p, t, alpha, i):\n",
    "    \"\"\"\n",
    "    Resource depletion (uptake and leakage reintroduction) for MiCRM.\n",
    "    \n",
    "    dx : array of length N+M (mutated in-place)\n",
    "    x  : current state vector\n",
    "    p  : parameter dict\n",
    "    t  : time (unused)\n",
    "    alpha : resource index\n",
    "    i     : consumer index\n",
    "    \"\"\"\n",
    "    idx = p['N'] + alpha\n",
    "    # uptake depletes resource\n",
    "    dx[idx] -= x[idx] * p['u'][i, alpha] * x[i] # x[i] is for consumers, and x[idx] is for resources\n",
    "    # leaked material from other resources\n",
    "    for beta in range(p['M']):\n",
    "        leak_idx = p['N'] + beta\n",
    "        dx[idx] += x[leak_idx] * x[i] * p['u'][i, beta] * p['l'][i, beta, alpha]\n",
    "\n",
    "\n",
    "\n",
    "# the MiCRM_dx and MiCRM_dxx functions are 2 versions of the full MiCRM \n",
    "# MiCRM_dx delegates each 'piece' of dynamics to 3 helper functions that we previously defined \n",
    "# this function here just computes derivatives. no callback.\n",
    "\n",
    "def MiCRM_dx(x, t, p,\n",
    "             growth=growth_MiCRM,\n",
    "             supply=supply_MiCRM,\n",
    "             depletion=depletion_MiCRM):\n",
    "    \"\"\"\n",
    "    Full derivative for MiCRM: consumer + resource dynamics.\n",
    "    \n",
    "    Returns a new dx array (length N+M).\n",
    "    \"\"\"\n",
    "    dx = np.zeros_like(x)\n",
    "    # consumer dynamics\n",
    "    for i in range(p['N']):\n",
    "        if x[i] > 1e-5: # anything smaller than this is seen as extinct \n",
    "            growth(dx, x, p, t, i)\n",
    "    # resource dynamics\n",
    "    for alpha in range(p['M']):\n",
    "        supply(dx, x, p, t, alpha)\n",
    "        for i in range(p['N']):\n",
    "            if x[i] > 1e-5:\n",
    "                depletion(dx, x, p, t, alpha, i)\n",
    "    return dx\n",
    "\n",
    "\n",
    "# below, the MiCRM_dxx function does not use helper functions defined outside of this function like growth_MiCRM\n",
    "# here, all the consumer and resource updates are directly written in one place, not split into helper functions \n",
    "# extinctions are not ignored here, it actually computes every term\n",
    "# no callback again (same as MiCRM_dx). as in, it keeps going, no condition to stop integrating \n",
    "\n",
    "\n",
    "\n",
    "def MiCRM_dxx(x, t, p):\n",
    "    \"\"\"\n",
    "    Combined MiCRM ODE right-hand side without callbacks.\n",
    "    \"\"\"\n",
    "    dx = np.zeros_like(x)\n",
    "    # consumers\n",
    "    for i in range(p['N']):\n",
    "        dx[i] = -p['m'][i] * x[i]\n",
    "        for alpha in range(p['M']):\n",
    "            res_idx = p['N'] + alpha\n",
    "            dx[i] += x[i] * x[res_idx] * p['u'][i, alpha]\n",
    "            for beta in range(p['M']):\n",
    "                dx[i] -= x[i] * x[res_idx] * p['u'][i, alpha] * p['l'][i, alpha, beta]\n",
    "    # resources\n",
    "    for alpha in range(p['M']):\n",
    "        idx = p['N'] + alpha\n",
    "        dx[idx] = p['rho'][alpha] - x[idx] * p['omega'][alpha]\n",
    "        for i in range(p['N']):\n",
    "            dx[idx] -= p['u'][i, alpha] * x[idx] * x[i]\n",
    "            for beta in range(p['M']):\n",
    "                leak_idx = p['N'] + beta\n",
    "                dx[idx] += x[leak_idx] * x[i] * p['u'][i, beta] * p['l'][i, beta, alpha]\n",
    "    return dx\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e8b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE OUT HOW THE DERIVATION WORKS! \n",
    "# i think here it just defines the terms like 'r' and 'aij' \n",
    "# but for the report, should understand better how the derivation works \n",
    "\n",
    "# from github EFF_LV_p_opt.jl, converted to python\n",
    "\n",
    "# this section defines parameters for effective GLV \n",
    "\n",
    "# notes from original jl file:\n",
    "# Function for calculating effective Lotka-Volterra parameters.\n",
    "# It is necessary to supply the parameters p and an ODE problem \n",
    "# solution containing equilibrium values for the system in question.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def eff_LV_params(p, sol, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate effective Lotka‐Volterra parameters from a MiCRM equilibrium.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p : dict\n",
    "        Parameter dict with keys:\n",
    "          - 'M','N'        : ints, number of resources and consumers\n",
    "          - 'l'            : leakage tensor, shape (N, M, M)\n",
    "          - 'rho','omega'  : resource supply and loss vectors, length M\n",
    "          - 'm'            : mortality vector, length N\n",
    "          - 'u'            : uptake matrix, shape (N, M)\n",
    "          - 'lambda'       : total leakage, shape (N, M)\n",
    "    sol : 2D array, shape (N+M, T_steps)\n",
    "        ODE solution; columns are timepoints, last column is equilibrium.\n",
    "    verbose : bool, default False\n",
    "        If True, also return the resource‐derivative matrix dR and the A matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        Always contains:\n",
    "          - 'alpha' : effective species interaction matrix (N×N)\n",
    "          - 'r'     : effective intrinsic growth rates (length N)\n",
    "          - 'N'     : number of consumers\n",
    "        If verbose:\n",
    "          - 'dR'    : ∂R/∂C matrix (M×N)\n",
    "          - 'A'     : resource‐interaction matrix (M×M)\n",
    "    \"\"\"\n",
    "    # Unpack\n",
    "    M, N = p['M'], p['N']\n",
    "    l = p['l']          # shape (N, M, M)\n",
    "    rho = p['rho']      # length M\n",
    "    omega = p['omega']  # length M\n",
    "    m = p['m']          # length N\n",
    "    u = p['u']          # shape (N, M)\n",
    "    lam = p['lambda']   # shape (N, M)\n",
    "    \n",
    "    # Kronecker delta\n",
    "    delta = lambda x, y: 1 if x == y else 0\n",
    "\n",
    "    # Equilibrium values (last column of sol)\n",
    "    Ceq = sol.y[:N, -1]          # consumer abundances at eq. -1 means the last column (last timestep)\n",
    "    Req = sol.y[N:, -1]          # resource abundances at eq. -1 means the last column (last timestep)\n",
    "    \n",
    "    # modified from sol to sol.y \n",
    "    \n",
    "    \n",
    "    # i don't think we've supplied what 'sol' is yet. \n",
    "    # when we call the function, we need to define some 'sol' \n",
    "    # and then pass that into the function (the function will find parameters for ELV) \n",
    "    # e.g. sol would be the result of some MiCRM equation, and then we pass that into this function, and it finds Ceq and Req from that sol \n",
    "    # and then uses Ceq and Req, along with other steps and derivations below, to find parameters for ELV \n",
    "\n",
    "\n",
    "\n",
    "    # 1) Build the resource‐interaction matrix A (shape M×M)\n",
    "    #    A_{αβ} = -ω_α + sum_i [ l[i,α,β]*u[i,β]*Ceq[i]  –  u[i,β]*Ceq[i]*δ(α,β) ]\n",
    "    A = np.zeros((M, M))\n",
    "    for α in range(M):\n",
    "        for β in range(M):\n",
    "            s = -omega[α]\n",
    "            for i in range(N):\n",
    "                s += l[i, α, β] * u[i, β] * Ceq[i]\n",
    "                if α == β:\n",
    "                    s -= u[i, β] * Ceq[i]\n",
    "            A[α, β] = s\n",
    "\n",
    "    # 2) Precompute inverse of A and the term u*(1–λ)\n",
    "    invA = np.linalg.inv(A)\n",
    "    A_thing = u * (1.0 - lam)   # shape (N, M)\n",
    "\n",
    "    # 3) Partial derivatives ∂R_α/∂C_j at equilibrium (shape M×N)\n",
    "    dR = np.zeros((M, N))\n",
    "    for α in range(M):\n",
    "        for j in range(N):\n",
    "            s = 0.0\n",
    "            for β in range(M):\n",
    "                for γ in range(M):\n",
    "                    s += invA[α, β] * u[j, β] * Req[γ] * (delta(β, γ) - l[j, β, γ])\n",
    "            dR[α, j] = s\n",
    "\n",
    "    # 4) Effective species‐species interaction matrix α_ij (shape N×N)\n",
    "    alpha = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            alpha[i, j] = np.sum(A_thing[i, :] * dR[:, j])\n",
    "\n",
    "    # 5) Components for intrinsic growth rates\n",
    "    O = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        O[i] = np.sum(A_thing[i, :] * Req)\n",
    "\n",
    "    P = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        P[i] = np.dot(alpha[i, :], Ceq)\n",
    "\n",
    "    # 6) Effective growth rates r_i = O_i – P_i – m_i\n",
    "    r_eff = O - P - m\n",
    "\n",
    "    # 7) Assemble results\n",
    "    result = {'alpha': alpha, 'r': r_eff, 'N': N}\n",
    "    if verbose:\n",
    "        result.update({'dR': dR, 'A': A})\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a0e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github LV_dx.jl, converted to python\n",
    "\n",
    "# now that we have the parameters for the effective GLV (parameters from previous section of code) we can define the Lotka-Volterra equations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def growth_LV(dx, x, p, t, i):\n",
    "    \"\"\"\n",
    "    Compute the per-species contribution to the derivative dx[i] \n",
    "    for species i in a Lotka-Volterra system.\n",
    "    Mutates the dx array in place.\n",
    "    \n",
    "    Arguments:\n",
    "      dx : 1D array (length N) of derivatives to update\n",
    "      x  : 1D array (length N) of current abundances\n",
    "      p  : dict of parameters, with keys:\n",
    "           - 'r': intrinsic growth rates (array of length N)\n",
    "           - 'alpha': interaction matrix (N x N array)\n",
    "           - 'N': number of species\n",
    "      t  : current time (unused here, but included for API consistency)\n",
    "      i  : index of the species to update\n",
    "    \"\"\"\n",
    "    dx[i] += p['r'][i] * x[i]\n",
    "    for j in range(p['N']):\n",
    "        dx[i] += x[i] * p['alpha'][i, j] * x[j]\n",
    "\n",
    "\n",
    "# growth_LV computes rate of change of a single species i in the Lotka-Volterra system\n",
    "# it adds the intrinsic growth term (r_i * x_i) \n",
    "# and then for each other species j, it adds the interaction term (alpha_ij * x_j)\n",
    "# this describes 1 species' contribution \n",
    "\n",
    "\n",
    "\n",
    "def LV_dx(x, t, p, growth=growth_LV):\n",
    "    \"\"\"\n",
    "    Compute the full derivative vector for the Lotka-Volterra system.\n",
    "    \n",
    "    Arguments:\n",
    "      x      : 1D array of current abundances\n",
    "      t      : current time\n",
    "      p      : dict of parameters (same as above)\n",
    "      growth : function to compute per-species updates (defaults to growth_LV)\n",
    "    \n",
    "    Returns:\n",
    "      dx : 1D array of derivatives for all species\n",
    "    \"\"\"\n",
    "    dx = np.zeros_like(x)\n",
    "    for i in range(p['N']):\n",
    "        # only apply growth if population is above machine precision\n",
    "        if x[i] > np.spacing(x[i]):\n",
    "            growth(dx, x, p, t, i)\n",
    "    return dx\n",
    "\n",
    "# dx is the actual rate of change of the system, which is a vector of length N\n",
    "# contains a whole system of LV differential equations, one for each species\n",
    "# this LV_dx function loops through all species i, and calls growth_LV for each one\n",
    "# the derivative vector dx can be passed to an ODE solver to compute the dynamics of the whole multi-species system over time \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# example usage:\n",
    "# params = {\n",
    "#     'N': 3,\n",
    "#     'r': np.array([0.1, 0.2, 0.15]),\n",
    "#     'alpha': np.array([[-0.01, -0.02, 0.0],\n",
    "#                        [0.01, -0.03, -0.01],\n",
    "#                        [0.0,  0.01, -0.02]])\n",
    "# }\n",
    "# x0 = np.array([1.0, 0.5, 0.2])\n",
    "# t = 0.0\n",
    "# dx = LV_dx(x0, t, params)\n",
    "# print(dx)\n",
    "# results would be [0.08   0.0965 0.0302] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c58ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from github Jacobian.jl, converted to python\n",
    "\n",
    "# this computes the Jacobian matrix \n",
    "# useful for downstream analysis on stability against perturbations \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def eff_LV_jac(p_lv, sol, threshold=1e-7):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian matrix of the effective GLV system\n",
    "    at equilibrium, restricted to the “feasible” subset of species.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_lv : dict\n",
    "        Output from eff_LV_params, with keys:\n",
    "          - 'alpha': full N×N interaction matrix\n",
    "          - 'r'    : length-N intrinsic growth rates\n",
    "          - 'N'    : total number of species\n",
    "    sol : OdeResult or similar\n",
    "        Solution object from solve_ivp on the MiCRM ODEs.\n",
    "        Expects sol.y shape = (N+M, n_timepoints)\n",
    "    threshold : float\n",
    "        Minimum equilibrium biomass to consider a species “present.”\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    LV_Jac : 2D array, shape (n_feasible, n_feasible)\n",
    "        The Jacobian ∂(dx)/∂x of the reduced Lotka–Volterra\n",
    "        system at equilibrium, only for species with biomass > threshold.\n",
    "    \"\"\"\n",
    "    # 1) Extract final biomasses for consumers\n",
    "    N_full = p_lv['N']\n",
    "    # sol.y: rows 0..N_full-1 are consumer abundances\n",
    "    bm = sol.y[:N_full, -1]\n",
    "\n",
    "    # 2) Identify \"feasible\" species (biomass above threshold)\n",
    "    feasible = np.where(bm > threshold)[0]\n",
    "    n = feasible.size\n",
    "\n",
    "    # 3) Subset the GLV parameters to those species\n",
    "    alpha_full = p_lv['alpha']\n",
    "    # Interaction submatrix\n",
    "    alpha = alpha_full[np.ix_(feasible, feasible)]\n",
    "    # Equilibrium biomasses for feasible species\n",
    "    C = bm[feasible]\n",
    "\n",
    "    # 4) Build the Jacobian: J_{ij} = α_{ij} * C_i\n",
    "    #      (since d x_i/dt = x_i (r_i + Σ_j α_{ij} x_j))\n",
    "    #      → ∂(dx_i)/∂x_j = δ_{i,j}(r_i + Σ_k α_{ik}C_k) + α_{ij} C_i\n",
    "    # For off-diagonals and simpler local stability, one often uses α_{ij} C_i.\n",
    "    LV_Jac = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            LV_Jac[i, j] = alpha[i, j] * C[i]\n",
    "\n",
    "    return LV_Jac\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from github MiCRM_jac_opt.jl \n",
    "# this code below calculates the Jacobian matrix for the MiCRM system \n",
    "\n",
    "\n",
    "def MiCRM_jac(p, sol):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian for the MiCRM system at the final timepoint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : dict\n",
    "        Model parameters with keys\n",
    "        - 'N'     : number of consumers\n",
    "        - 'M'     : number of resources\n",
    "        - 'λ'     : (N×M) matrix of leakage fractions\n",
    "        - 'l'     : (N×M×M) stoichiometry tensor\n",
    "        - 'ρ'     : (unused in Jacobian here, but typically inflow rates)\n",
    "        - 'ω'     : length-M vector of resource washout rates\n",
    "        - 'm'     : length-N vector of consumer mortality rates\n",
    "        - 'u'     : (N×M) uptake rates\n",
    "    sol : OdeResult‐like\n",
    "        Must have `sol.y` of shape `(N+M, n_timepoints)`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    J : ndarray, shape (N+M, N+M)\n",
    "        Full Jacobian ∂(d[Consumers,Resources])/∂[Consumers,Resources]\n",
    "    \"\"\"\n",
    "    N = p['N']\n",
    "    M = p['M']\n",
    "    lam = p['lambda']      # shape (N, M)\n",
    "    l   = p['l']      # shape (N, M, M)\n",
    "    ω   = p['omega']      # shape (M,)\n",
    "    m   = p['m']      # shape (N,)\n",
    "    u   = p['u']      # shape (N, M)\n",
    "\n",
    "    # final state\n",
    "    state = sol.y[:, -1]\n",
    "    C = state[:N]     # consumer biomasses\n",
    "    R = state[N:]     # resource concentrations\n",
    "\n",
    "    # allocate Jacobian\n",
    "    J = np.zeros((N+M, N+M))\n",
    "\n",
    "    # ——— Consumer–Consumer block (top‐left N×N) ———\n",
    "    # diag entries: ∂(dC_i)/∂C_i\n",
    "    for i in range(N):\n",
    "        J[i, i] = -m[i] + np.sum((1 - lam[i, :]) * u[i, :] * R)\n",
    "    # off‐diagonals are zero by model structure\n",
    "\n",
    "    # ——— Consumer–Resource block (top‐right N×M) ———\n",
    "    # ∂(dC_i)/∂R_α = C_i * (1−λ_{iα}) * u_{iα}\n",
    "    for i in range(N):\n",
    "        for α in range(M):\n",
    "            J[i, N+α] = C[i] * (1 - lam[i, α]) * u[i, α]\n",
    "\n",
    "    # ——— Resource–Resource block (bottom‐right M×M) ———\n",
    "    # diag: ∂(dR_α)/∂R_α \n",
    "    for α in range(M):\n",
    "        J[N+α, N+α] = -ω[α] + np.sum(C * u[:, α] * (l[:, α, α] - 1))\n",
    "    # off‐diagonals: ∂(dR_α)/∂R_β for β≠α\n",
    "    for α in range(M):\n",
    "        for β in range(M):\n",
    "            if β != α:\n",
    "                J[N+α, N+β] = np.sum(C * u[:, β] * l[:, β, α])\n",
    "\n",
    "    # ——— Resource–Consumer block (bottom‐left M×N) ———\n",
    "    # ∂(dR_α)/∂C_i = -u_{iα} * R_α + Σ_β l_{iβ,α} u_{iβ} R_β\n",
    "    for α in range(M):\n",
    "        for i in range(N):\n",
    "            term1 = -u[i, α] * R[α]\n",
    "            term2 = np.sum(l[i, :, α] * u[i, :] * R)\n",
    "            J[N+α, i] = term1 + term2\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "\n",
    "##### BELOW CODE SHOULD BE APPLICABLE FOR BOTH GLVM + MICRM EIGENVALUE CALCULATIONS #####\n",
    "\n",
    "def leading_eigenvalue(J): \n",
    "    \"\"\"\n",
    "    Compute the dominant eigenvalue (largest real part) of Jacobian matrix J.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(J)\n",
    "    return eigvals[np.argmax(np.real(eigvals))]\n",
    "\n",
    "\n",
    "def hermitian_part(J):\n",
    "    \"\"\"\n",
    "    Return the Hermitian (symmetric) part of a real matrix J: (J + J.T) / 2.\n",
    "    \"\"\"\n",
    "    return (J + J.T) / 2\n",
    "\n",
    "\n",
    "def leading_hermitian_eigenvalue(J):\n",
    "    \"\"\"\n",
    "    Compute the leading eigenvalue of the Hermitian part of J,\n",
    "    which indicates the reactivity of the system.\n",
    "    \"\"\"\n",
    "    H = hermitian_part(J)\n",
    "    # For symmetric H, use eigvalsh for efficiency and guaranteed real outputs\n",
    "    eigvals = np.linalg.eigvalsh(H)\n",
    "    return np.max(eigvals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e60917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nremoved some irrelevant functions previously in code\\n\\n- cosine similarity\\n- euclidean distance\\n- bray curtis dissimilarity (have modified and included this later on) \\n- AIC - Akaike information criterion \\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from github sim_frame.jl, converted to python. sim_frame.jl includes the previous 6 files.\n",
    " \n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from scipy.stats import dirichlet\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "# ————————————————————————————————————————————————\n",
    "# Custom MiCRM‐parameter‐generator functions (override defaults)\n",
    "# ————————————————————————————————————————————————\n",
    "\n",
    "def F_m(N, M, kw):\n",
    "    \"\"\"\n",
    "    Temperature‐dependent mortality (maintenance) rates.\n",
    "    If 'tt' is in kw (an Nx2 array of TPC scalings), use the 2nd column;\n",
    "    otherwise fallback to a constant 0.2 for each species.\n",
    "    \"\"\"\n",
    "    if 'tt' in kw:\n",
    "        # kw['tt'] assumed shape (N,2)\n",
    "        return kw['tt'][:, 1] # this is the respiration/mortality part of 'tt', defined before. used to be temp_p_m.\n",
    "    else:\n",
    "        return np.full(N, 0.2)\n",
    "\n",
    "def F_rho(N, M, kw):\n",
    "    \"\"\"\n",
    "    Resource supply rates: constant ones by default.\n",
    "    \"\"\"\n",
    "    return np.ones(M)\n",
    "\n",
    "# could introduce temperature-dependence in this if we want to look at temp-dependent resource supply \n",
    "# same with omega below, seeing how temp affects loss/dilution of resources in specific ecosystems \n",
    "\n",
    "def F_omega(N, M, kw):\n",
    "    \"\"\"\n",
    "    Resource loss/dilution rates: zero by default.\n",
    "    \"\"\"\n",
    "    return np.zeros(M)\n",
    "\n",
    "def F_u(N, M, kw):\n",
    "    \"\"\"\n",
    "    Temperature‐scaled uptake matrix.\n",
    "      - Draws N Dirichlet(1,…,1) rows of length M (relative preference).\n",
    "      - Scales each row i by kw['tt'][i,0] if present, else by 2.5.\n",
    "    \"\"\"\n",
    "    # draw relative preferences\n",
    "    diri = np.stack([rng.dirichlet(np.ones(M)) for _ in range(N)], axis=0)\n",
    "    \n",
    "    if 'tt' in kw:\n",
    "        u_sum = kw['tt'][:, 0] # this is the uptake part of 'tt', defined before. used to be temp_p_u. \n",
    "    else:\n",
    "        u_sum = np.full(N, 2.5)\n",
    "    \n",
    "    # scale each row by its TPC magnitude\n",
    "    return diri * u_sum[:, None]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "removed some irrelevant functions previously in code\n",
    "\n",
    "- cosine similarity\n",
    "- euclidean distance\n",
    "- bray curtis dissimilarity (have modified and included this later on) \n",
    "- AIC - Akaike information criterion \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de27e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for diversity \n",
    "\n",
    "\n",
    "##### Shannon diversity #####\n",
    "\n",
    "def shannon (abundance): # abundance should be an array (incl values for all consumers in system) \n",
    "    C_shannon = np.asarray(abundance, dtype=float) # convert into numpy arrays of floats \n",
    "  \n",
    "    ### normalise to convert abundance into something on a scale of 0-1 ###\n",
    "\n",
    "    # total number of 'individuals' (add up all the relative abundances) \n",
    "    total_abundance = np.sum(C_shannon) # add up all the elements in this C_shannon array. total_abundance also a single value. \n",
    "\n",
    "    pi = C_shannon / total_abundance # pi is  an array. it now converts C_shannon into relative proportions, by dividing each element of C_shannon by the total_abundance value. \n",
    "\n",
    "    pi_lnpi = pi[pi > 0] * np.log(pi[pi > 0]) # this is pi * ln(pi). pi_lnpi should also be an array with N elements. \n",
    "    # keep only the pi > 0 ones. if pi = 0, will have issues with log. if pi = 0 it won't contribute to Shannon index anyway. \n",
    "\n",
    "    H = -np.sum(pi_lnpi) \n",
    "\n",
    "    return H \n",
    "\n",
    "# note: for Shannon diversity, might need to consider the case where total abundance is 0 (so would be dividing by 0)\n",
    "\n",
    "# can compare Shannon diversity for 2 samples (GLV vs MiCRM for each temperature)\n",
    "\n",
    "##### Bray-Curtis dissimilarity ##### \n",
    "\n",
    "# defined earlier already, but re-write anyway \n",
    "\n",
    "\n",
    "def bray_curtis_dissimilarity(G, M): # G = GLV, M = MiCRM \n",
    "\n",
    "    G_array = np.asarray(G, dtype=float) # convert G (abundance of each species predicted by GLV) into array \n",
    "    M_array = np.asarray(M, dtype=float) # convert M (abundance of each species predicted by MiCRM) into array \n",
    "\n",
    "    G_safe = np.where(G_array < 0, 0, G_array) # if any element (species) of the GLV-predicted array of abundances is less than 0, consider that 0\n",
    "    M_safe = np.where(M_array < 0, 0, M_array) \n",
    "\n",
    "    GM_dissimilarity = np.sum(np.abs(G_safe - M_safe)) / np.sum(G_safe + M_safe) # bray-curtis dissimilarity between GLV and MiCRM predictions \n",
    "\n",
    "    return GM_dissimilarity \n",
    "\n",
    "# also consider the case where total abundance is 0 (so would be dividing by 0) \n",
    "\n",
    "\n",
    "### Jaccard ###\n",
    "\n",
    "def jaccard_index(G, M, thresh=1e-8):\n",
    "    \"\"\"\n",
    "    Jaccard index J = |A ∩ B| / |A ∪ B| for presence/absence sets.\n",
    "    Presence := abundance > thresh.\n",
    "    Returns 1.0 if both sets are empty.\n",
    "    \"\"\"\n",
    "    G = np.asarray(G, dtype=float)\n",
    "    M = np.asarray(M, dtype=float)\n",
    "    if G.shape != M.shape:\n",
    "        raise ValueError(\"G and M must have same shape\")\n",
    "    G_surv = G > thresh\n",
    "    M_surv = M > thresh\n",
    "    inter = np.logical_and(G_surv, M_surv).sum()\n",
    "    union = np.logical_or(G_surv, M_surv).sum()\n",
    "    return 1.0 if union == 0 else inter / union\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2047a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define functions for abundance deviation + species overlap between MiCRM and EGLV ###\n",
    "\n",
    "\"\"\"\n",
    "this is for each community simulation (N consumers), for each temperature\n",
    "to be incorporated into the later functions and loops (loop this function for each temp, then for each community simulation)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def err_eq_and_overlap(C_LV_eq, C_MiCRM_eq, thresh=1e-6):\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "    - Mean log-ratio error in predicted abundances (GLV vs MiCRM) \n",
    "    - Number of overlapping survivors (identity-based overlap)\n",
    "\n",
    "    Only includes species that are predicted to survive by *both* models.\n",
    "\n",
    "    Inputs:\n",
    "    - C_LV_eq: GLV-predicted equilibrium consumer abundances (array-like)\n",
    "    - C_MiCRM_eq: MiCRM-predicted equilibrium consumer abundances (array-like)\n",
    "    - thresh: threshold below which species are considered extinct\n",
    "    - eps: small pseudocount to avoid log(0)\n",
    "\n",
    "    Returns:\n",
    "    - equilibrium_error: mean log-ratio error between GLV and MiCRM (NaN if no shared survivors)\n",
    "    - overlap_count: number of species predicted to survive by both models\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to float arrays\n",
    "    C_LV = np.asarray(C_LV_eq, dtype=float)\n",
    "    C_Mi = np.asarray(C_MiCRM_eq, dtype=float)\n",
    "\n",
    "    # Identify survivors (boolean masks)\n",
    "    G_surv = C_LV > thresh\n",
    "    M_surv = C_Mi > thresh\n",
    "\n",
    "    # Overlap mask: species that survive in BOTH models\n",
    "    overlap_mask = G_surv & M_surv # element-wise check, so overlap_mask is true only if BOTH G_surv and M_surv are true for a species \n",
    "    overlap_count = np.sum(overlap_mask) # counts how many TRUE entries there are (size of intersection for survivors) \n",
    "\n",
    "    if overlap_count == 0:\n",
    "        return np.nan, 0  # No shared survivors, can't compute meaningful abundance deviation\n",
    "\n",
    "\n",
    "    # Log ratio of overlapping species\n",
    "    log_ratios = np.log(C_LV[overlap_mask] / C_Mi[overlap_mask])\n",
    "    equilibrium_error = np.mean(log_ratios)\n",
    "\n",
    "    return equilibrium_error, overlap_count\n",
    "\n",
    "\n",
    "# define function to produce the Err(t) function showing deviations over time\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def err_time_series(\n",
    "    times,       # 1D array of time‐points (shape (T,)), e.g. [0, 5, 10, …, 5000]\n",
    "    C_LV_traj,   # 2D array of GLV abundances, shape (N, T)\n",
    "    C_Mi_traj,   # 2D array of MiCRM abundances, shape (N, T)\n",
    "    thresh=1e-6  # below this abundance we call a species “extinct”\n",
    "    ):\n",
    "    \"\"\"\n",
    "    For each time point t_j, compute:\n",
    "      - Err(t_j) = mean_i log( C_LV[i,j] / C_Mi[i,j] ) over species surviving in BOTH models\n",
    "      - overlap_counts[j] = how many species survive in both at t_j\n",
    "    Returns two arrays, each of length T.\n",
    "\n",
    "    note: 'j' is a loop index (for time), running from j = 0 to j = T-1 (last timepoint) \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack dimensions from the trajectories\n",
    "    N, T = C_LV_traj.shape  \n",
    "    #   N = number of species\n",
    "    #   T = number of timepoints \n",
    "\n",
    "    # Pre‐allocate output arrays\n",
    "    err_t          = np.empty(T, dtype=float)   # will hold Err(t_j) for j=0…T-1\n",
    "    overlap_counts = np.empty(T, dtype=int)     # will hold overlap_counts[j]\n",
    "\n",
    "    # Loop over each time‐index j\n",
    "    for j in range(T):\n",
    "        # j is the integer index of the time‐point (0 ≤ j < T)\n",
    "        # time = times[j]  # could use this if you wanted to stamp the time, but we only need j\n",
    "\n",
    "        # Extract the N‐vector of abundances at time‐point j\n",
    "        C_LV_j = C_LV_traj[:, j]   # shape (N,)\n",
    "        C_Mi_j = C_Mi_traj[:, j]   # shape (N,)\n",
    "\n",
    "        # Boolean masks for who is “alive” in each model at t_j\n",
    "        G_surv = C_LV_j > thresh   # True for species with LV‐abundance > thresh\n",
    "        M_surv = C_Mi_j > thresh   # True for species with MiCRM‐abundance > thresh\n",
    "\n",
    "        # Only keep those that survive in *both*\n",
    "        mask = G_surv & M_surv      # element‐wise AND, shape (N,)\n",
    "        overlap_counts[j] = mask.sum()  # count how many True’s\n",
    "\n",
    "        if overlap_counts[j] == 0:\n",
    "            # No species overlap → no meaningful log‐ratio\n",
    "            err_t[j] = np.nan\n",
    "        else:\n",
    "            # Compute log‐ratios only on the overlapping survivors\n",
    "            log_ratios = np.log(C_LV_j[mask] / C_Mi_j[mask])\n",
    "            err_t[j]   = np.mean(log_ratios)\n",
    "\n",
    "    return err_t, overlap_counts\n",
    "\n",
    "\n",
    "\n",
    "# define function to produce the Errtraj, which integrates Err(t) and finds area under curve. represents trajectory deviation. \n",
    "\n",
    "def integrate_err(\n",
    "    times,  # 1D array of time‐points, shape (T,)\n",
    "    err_t   # 1D array of instantaneous errors, shape (T,)\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Compute the time‐averaged trajectory error\n",
    "      Err_traj = (1/(t_end - t_start)) * ∫ Err(t) dt\n",
    "    using the trapezoid rule on the discrete grid.\n",
    "    Returns a single float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mask out any NaNs (where overlap = 0)\n",
    "    valid     = ~np.isnan(err_t)\n",
    "    t_valid   = times[valid]   # times where err_t is real\n",
    "    err_valid = err_t[valid]   # corresponding error values\n",
    "\n",
    "    # Need at least 2 points to do any integration\n",
    "    if valid.sum() < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # Numerically integrate Err(t) dt by the trapezoid rule:\n",
    "    integral = np.trapz(err_valid, x=t_valid)\n",
    "\n",
    "    # Divide by total time to get *average* error\n",
    "    duration = t_valid[-1] - t_valid[0]  # here, t_valid[-1] == t_end\n",
    "    return integral / duration\n",
    "\n",
    "\n",
    "# when finding trajectory error, we only want to find it up to teq (time where both systems reach equilibrium) \n",
    "# hence we define this function below to work out the equilibrium states \n",
    "\n",
    "\n",
    "def estimate_teq(\n",
    "    times,    # 1D array of sampled times, shape (T,)\n",
    "    sol,      # MiCRM solution object from solve_ivp\n",
    "    sol_lv,   # GLV   solution object from solve_ivp\n",
    "    pT,       # parameter dict used for MiCRM_dxx\n",
    "    p_lv,     # parameter dict used for LV_dx\n",
    "    tol=1e-6, # threshold on derivative‐norm to call “flat”\n",
    "    window=5  # require this many consecutive below‐tol points\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Estimate the index j_eq corresponding to the time t_eq when BOTH\n",
    "    MiCRM and GLV trajectories have effectively reached steady‐state.\n",
    "    We do this by looking at the derivative norms ||dx/dt|| of each\n",
    "    system at each sampled time, taking their maximum, and finding the\n",
    "    first run of `window` consecutive samples all below `tol`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    j_eq : int\n",
    "      Index into `times` such that times[j_eq] is our estimated t_eq.\n",
    "      If no such run is found, returns T-1 (i.e., the last time index).\n",
    "    \"\"\"\n",
    "\n",
    "    T = times.size\n",
    "    # Prepare an array to store [||dx_mi||, ||dx_lv||] at each time\n",
    "    deriv_norms = np.empty((T, 2), dtype=float)\n",
    "\n",
    "    # Derive species count of consumers from sol_lv\n",
    "    N_lv = sol_lv.y.shape[0]\n",
    "\n",
    "    # Loop over each sampled time index\n",
    "    for j, t in enumerate(times):\n",
    "        # 1) MiCRM derivative at this time:\n",
    "        x_mi       = sol.y[:, j]                      # state vector length N+M\n",
    "        dx_mi      = MiCRM_dxx(x_mi, t, pT)            # compute RHS\n",
    "        deriv_norms[j, 0] = norm(dx_mi)                # Euclidean norm\n",
    "        \n",
    "        # 2)  GLV derivative at this time:\n",
    "        x_lv       = sol_lv.y[:, j]                   # state vector length N\n",
    "        dx_lv      = LV_dx(x_lv, t, p_lv)             # compute RHS\n",
    "        deriv_norms[j, 1] = norm(dx_lv)               # Euclidean norm\n",
    "\n",
    "    # At each time j, take the worst‐case (largest) of the two norms\n",
    "    combined_norm = np.max(deriv_norms, axis=1)       # shape (T,)\n",
    "\n",
    "    # Now find the first index j where combined_norm[j:(j+window)]\n",
    "    # are all < tol, i.e. both models stay flat for `window` steps\n",
    "    for j in range(0, T - window + 1):\n",
    "        # Check the next `window` points\n",
    "        if np.all(combined_norm[j : j + window] < tol):\n",
    "            # Once found, return j as the equilibrium index\n",
    "            return j\n",
    "\n",
    "    # If we never see `window` consecutive small‐derivative points, \n",
    "    # we assume equilibrium is at the final time\n",
    "    return T - 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Investigating the effect of temperature on higher-order interactions\n",
    "Hessian = second derivative \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 1) Define F_of_C: consumer-only vector field with resources at steady state\n",
    "def F_of_C(C, p):\n",
    "    \"\"\"\n",
    "    Compute dC/dt = F(C) for MiCRM with resources assumed at steady state R*(C).\n",
    "    - C: length-N consumer vector.\n",
    "    - p: full parameter dict with 'N','M','u','lambda','rho','omega','l'.\n",
    "    Returns: dC (length N).\n",
    "    \"\"\"\n",
    "    N, M = p['N'], p['M']\n",
    "    u, lam = p['u'], p['lambda']  # shapes (N,M)\n",
    "    rho, omega, l = p['rho'], p['omega'], p['l']  # rho:(M,), omega:(M,), l:(N,M,M)\n",
    "\n",
    "    # Build A(C) matrix (M x M)\n",
    "    A = np.zeros((M, M))\n",
    "    for a in range(M):\n",
    "        for b in range(M):\n",
    "            s = -omega[a]\n",
    "            for i in range(N):\n",
    "                s += l[i, a, b] * u[i, b] * C[i]\n",
    "                if a == b:\n",
    "                    s -= u[i, b] * C[i]\n",
    "            A[a, b] = s\n",
    "\n",
    "    # Solve for R*: A @ R = rho\n",
    "    R_star = np.linalg.solve(A, rho)\n",
    "\n",
    "    # Compute dC/dt = C * [(1-lambda)*u @ R_star - m]\n",
    "    growth_term = (1 - lam) * u  # (N,M)\n",
    "    net = growth_term.dot(R_star) - p['m']  # length N\n",
    "    return C * net\n",
    "\n",
    "# 2) Finite-difference Hessian norm\n",
    "\n",
    "def compute_hessian_norm(C_eq, p, F, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Approximate Frobenius norm of Hessian H_ijk = d^2 F_i / dC_j dC_k\n",
    "    at C_eq, via central differences.\n",
    "    F: function F(C,p) -> dC/dt vector\n",
    "    \"\"\"\n",
    "    N = C_eq.size\n",
    "    H2_sum = 0.0\n",
    "    # base value\n",
    "    F0 = F(C_eq, p)\n",
    "    for j in range(N):\n",
    "        for k in range(N):\n",
    "            e_j = np.zeros(N); e_j[j] = eps\n",
    "            e_k = np.zeros(N); e_k[k] = eps\n",
    "            F_pp = F(C_eq + e_j + e_k, p)\n",
    "            F_pm = F(C_eq + e_j - e_k, p)\n",
    "            F_mp = F(C_eq - e_j + e_k, p)\n",
    "            F_mm = F(C_eq - e_j - e_k, p)\n",
    "            # second partial derivative vector\n",
    "            H_jk = (F_pp - F_pm - F_mp + F_mm) / (4 * eps * eps)\n",
    "            H2_sum += np.sum(H_jk**2)\n",
    "    return np.sqrt(H2_sum)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_row_diagonally_dominant(J, tol=1.0):\n",
    "    \"\"\"\n",
    "    Check if every row of square matrix J is diagonally dominated:\n",
    "        |J[ii]| >= tol * sum_{j!=i} |J[ij]|\n",
    "    Returns a boolean array of length J.shape[0], True where row i is dominated.\n",
    "    \"\"\"\n",
    "    J = np.asarray(J)\n",
    "    absJ = np.abs(J)\n",
    "    diag = absJ.diagonal()\n",
    "    offdiag_sums = absJ.sum(axis=1) - diag\n",
    "    return diag >= tol * offdiag_sums\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "If the rows are no longer diagonally dominant (e.g. at higher temperatures),\n",
    "then it's not valid to use the shortcut to estimate timescale separation. \n",
    "Would need to use the function below. \n",
    "\n",
    "Option 1) just use the full method \n",
    "Option 2) use the shortcut, but justify by showing that it's still valid (diagonally dominant) \n",
    "\n",
    "Learning toward using option 1) because we could argue that higher temp -> less diagonal dominance (more interactions) -> more reactivity \n",
    "\"\"\"\n",
    "\n",
    "def timescale_separation_full(J_full, N):\n",
    "    \"\"\"\n",
    "    Given the full (N+M)x(N+M) MiCRM Jacobian J_full and number of consumers N,\n",
    "    returns (tau_C, tau_R, epsilon) by eigenmode classification.\n",
    "    \"\"\"\n",
    "    # 1) eigendecompose\n",
    "    eigvals, eigvecs = np.linalg.eig(J_full)\n",
    "    re_times = 1.0 / np.abs(np.real(eigvals))\n",
    "\n",
    "    # 2) classify modes by where v has more weight\n",
    "    #    sum |v[i]| over consumers vs. resources\n",
    "    weights = np.abs(eigvecs)\n",
    "    cons_weight = weights[:N, :].sum(axis=0)\n",
    "    res_weight  = weights[N:, :].sum(axis=0)\n",
    "\n",
    "    cons_mask = cons_weight >= res_weight\n",
    "    res_mask  = ~cons_mask\n",
    "\n",
    "    # 3) select timescales\n",
    "    #    - consumers: fastest return (smallest tau)\n",
    "    #    - resources: slowest return (largest tau)\n",
    "    if not np.any(cons_mask) or not np.any(res_mask):\n",
    "        raise ValueError(\"No pure consumer or resource modes found!\")\n",
    "    tau_C = np.min(re_times[cons_mask])\n",
    "    tau_R = np.max(re_times[res_mask])\n",
    "\n",
    "    # 4) separation\n",
    "    epsilon = tau_C / tau_R\n",
    "    return tau_C, tau_R, epsilon\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f57826",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_760\\2106978782.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     sol = solve_ivp(\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMiCRM_dxx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mt_span\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_max_micrm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[1;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'finished'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\bdf.py\u001b[0m in \u001b[0;36m_step_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcurrent_jac\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                     \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m                     \u001b[0mLU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m                     \u001b[0mcurrent_jac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\bdf.py\u001b[0m in \u001b[0;36mjac_wrapped\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnjev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                 J, self.jac_factor = num_jac(self.fun_vectorized, t, y, f,\n\u001b[0m\u001b[0;32m    262\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                                              sparsity)\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\common.py\u001b[0m in \u001b[0;36mnum_jac\u001b[1;34m(fun, t, y, f, threshold, factor, sparsity)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_dense_num_jac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparsity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\common.py\u001b[0m in \u001b[0;36m_dense_num_jac\u001b[1;34m(fun, t, y, f, h, factor, y_scale)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[0mh_vecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0mf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_new\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mmax_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py\u001b[0m in \u001b[0;36mfun_vectorized\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                     \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chan Li\\anaconda3\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_760\\2106978782.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     sol = solve_ivp(\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMiCRM_dxx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mt_span\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_max_micrm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_760\\2605424809.py\u001b[0m in \u001b[0;36mMiCRM_dxx\u001b[1;34m(x, t, p)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[0mdx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m                 \u001b[0mdx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'l'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;31m# resources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################# PRODUCING ACTUAL SIMULATION GRAPHS #############################\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from scipy.integrate import solve_ivp\n",
    "from numpy import linspace \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "want to first generate parameters for a particular randomly-assembled community\n",
    "and then simulate 31 different temperatures for this same community (both MiCRM and EGLV graphs for each temperature) \n",
    "compare how temperature affects the deviation between MiCRM and EGLV graphs\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rng = default_rng(111)\n",
    "\n",
    "N = 50\n",
    "M = 25\n",
    "L = np.full(N, 0.3) # leakage (this is not temp dependent, as per original MiCRM)\n",
    "\n",
    "x0 = np.concatenate([np.full(N, 0.1), np.full(M, 1)]) # initial conditions for consumers and resources\n",
    "\n",
    "# Temperature‐dependence parameters\n",
    "num_temps = 31 # number of temperatures\n",
    "rho_t = np.array([0.0, 0.0])   # minimal trade‐off\n",
    "Tr = 273.15 + 10 # reference temperature (10 °C)\n",
    "Ed = 3.5 \n",
    "\n",
    "\n",
    "\n",
    "####### TEST OUT DIFFERENT TEMPERATURES #######\n",
    "\n",
    "\n",
    "structural = generate_params(\n",
    "    N, M,\n",
    "    f_u=def_u,      # relative preferences only\n",
    "    f_m=def_m,      # placeholder\n",
    "    f_rho=def_rho,\n",
    "    f_omega=def_omega,\n",
    "    f_l=def_l,\n",
    "    # *no* T, Tr, Ed, rho_t here\n",
    "    L=L,\n",
    "    T=273.15,   # dummy (This satisfies temp_trait’s requirement that kw contain T, rho_t, Tr, Ed) \n",
    "    # since we are using the default def_u and def_m here, they ignore kw, so any T will work \n",
    "    # this whole thing will just provide relative preferences (u) and a constant m=1    \n",
    "    rho_t=rho_t,  # dummy\n",
    "    Tr=Tr,        # dummy\n",
    "    Ed=Ed         # dummy\n",
    ")\n",
    "\n",
    "# the 'structural' parameters are static and don't change with temperature\n",
    "# e.g. the def_u only generates relative preferences, not absolute ones\n",
    "# however the uptake rate (u) will change with temperature. the relative preferences won't. \n",
    "# other things like rho and omega also don't change with temperature\n",
    "\n",
    "\n",
    "\n",
    "temp_vals = linspace(273.15, 273.15 + 30, num_temps) # 31 temperatures from 0 to 30 degrees C\n",
    "\n",
    "results = [] # store results for each temperature. it is a list of dictionaries. each temp would produce its own dictionary. \n",
    "\n",
    "for T in temp_vals:\n",
    "\n",
    "    # temp-dependent scalars\n",
    "\n",
    "    temp_p, B, E, Tp = temp_trait(N, {\n",
    "        'T': T, 'Tr': Tr, 'Ed': Ed, 'rho_t': rho_t, 'L': L\n",
    "    })\n",
    "    temp_p_u = temp_p[:,0]\n",
    "    temp_p_m = temp_p[:,1]\n",
    "\n",
    "    # full parameter dictionary for this temp\n",
    "\n",
    "    pT = {\n",
    "        **structural,            # brings in u_pref, l, B, E, Tp, L, N, M, etc.\n",
    "        'u': structural['u'] * temp_p_u[:,None],  # absolute uptake rates. the preference matrix from structural['u'] is multiplied (scaled) by the temperature-dependent uptake rates\n",
    "        'm': temp_p_m,                            # mortality rates. the preference matrix from structural['m'] is multiplied (scaled) by the temperature-dependent mortality rates\n",
    "        'lambda': np.sum(structural['l'], axis=2),\n",
    "        'T': T\n",
    "    }   \n",
    "    \n",
    "\n",
    "    # set up integration range\n",
    "\n",
    "    t_max_micrm = 300\n",
    "    t_max_glv   = 300\n",
    "\n",
    "    t_eval_micrm = np.linspace(0, t_max_micrm, 300)\n",
    "    t_eval_glv   = np.linspace(0, t_max_glv,   300)\n",
    "\n",
    "\n",
    "    # solve MiCRM at this temperature\n",
    "    \n",
    "\n",
    "    sol = solve_ivp(\n",
    "        lambda t, y: MiCRM_dxx(y, t, pT),\n",
    "        t_span=(0, t_max_micrm),\n",
    "        y0=x0,\n",
    "        method='BDF',\n",
    "        t_eval=t_eval_micrm \n",
    "    )\n",
    "\n",
    "    \n",
    "    # solve EGLV at this temperature\n",
    "    \n",
    "    p_lv = eff_LV_params(pT, sol, verbose=False)\n",
    "\n",
    "    sol_lv = solve_ivp(\n",
    "        lambda t, y: LV_dx(y, t, p_lv),\n",
    "        t_span=(0, t_max_glv), \n",
    "        y0=sol.y[:N, 0],\n",
    "        method='BDF', \n",
    "        t_eval=t_eval_glv        \n",
    "        )\n",
    "    \n",
    "    ##### deviation calculations #####\n",
    "\n",
    "    # first collect the equilibrium values for MiCRM and GLV (this is the last value in time series, t1)\n",
    "    times      = sol.t\n",
    "    C_MiCRM_eq = sol.y[:N, -1] # equilibrium consumer biomass\n",
    "    C_LV_eq = sol_lv.y[:N, -1] # equilibrium consumer biomass\n",
    "\n",
    "       \n",
    "    # equilibrium abundance deviation \n",
    "    ErrEqAb, overlap = err_eq_and_overlap(C_LV_eq, C_MiCRM_eq)\n",
    "\n",
    "    # trajectory deviation  \n",
    "    times      = sol.t                   # shape (T,). this defines the time array to be investigated in trajectory deviations \n",
    "    C_Mi_traj  = sol.y[:N, :]            # shape (N, T). this is the MiCRM trajectory, to be analysed in trajectory deviations \n",
    "    C_LV_traj  = sol_lv.y[:N, :]         # shape (N, T). this is the GLVM trajectory, to be analysed in trajectory deviations \n",
    "    err_t, overlap_t = err_time_series(times, C_LV_traj, C_Mi_traj) # first get the time series \n",
    "    j_eq = estimate_teq(times, sol, sol_lv, pT, p_lv, tol=1e-6, window=5) # find equilibrium time \n",
    "    times_crop = times[: j_eq + 1] # crop time array to equilibrium \n",
    "    err_crop   = err_t[: j_eq + 1] # crop trajectory error array to equilibrium \n",
    "    Err_traj = integrate_err(times_crop, err_crop) # integrate over [0, t_eq] instead of [0, t_max]\n",
    "    j_eq   = estimate_teq(times, sol, sol_lv, pT, p_lv, tol=1e-6, window=5) # equilibrium time index (for timescale sep) \n",
    "    t_eq   = times[j_eq] # convert to actual time \n",
    "\n",
    "    # diversity deviation\n",
    "    jaccard = jaccard_index(C_LV_eq, C_MiCRM_eq, thresh=1e-6)\n",
    "    sh_LV = shannon(C_LV_eq)\n",
    "    sh_Mi = shannon(C_MiCRM_eq)\n",
    "    bc = bray_curtis_dissimilarity(C_LV_eq, C_MiCRM_eq)\n",
    "\n",
    "    # stability (Jacobian) and reactivity (Hermitian) \n",
    "    J_glv   = eff_LV_jac(p_lv, sol)\n",
    "    stab_glv  = leading_eigenvalue(J_glv)\n",
    "    react_glv = leading_hermitian_eigenvalue(J_glv)\n",
    "\n",
    "    J_micrm   = MiCRM_jac(pT, sol)\n",
    "    stab_mic  = leading_eigenvalue(J_micrm)\n",
    "    react_mic = leading_hermitian_eigenvalue(J_micrm)\n",
    "\n",
    "    # timescale separation (using full method, not simplified)\n",
    "    tau_C, tau_R, epsilon = timescale_separation_full(J_micrm, N)\n",
    "\n",
    "    # Hessian norm at consumer equilibrium\n",
    "    C_eq = C_MiCRM_eq  # your equilibrium consumers\n",
    "    hess_norm = compute_hessian_norm(C_eq, pT, F_of_C)\n",
    "\n",
    "    # non‐normality\n",
    "    comm      = J_micrm @ J_micrm.T - J_micrm.T @ J_micrm\n",
    "    nnorm     = np.linalg.norm(comm, ord='fro')\n",
    "\n",
    "    # investigating bauer-fike and explaining stability changes\n",
    "\n",
    "    \"\"\"\n",
    "    was getting an error that the size of micrm jacobian and size of glv jacobian are different\n",
    "    because glv only contains 'feasible' species\n",
    "    so need to reduce micrm jacobian to also the 'feasible' species (can then make a fair comparison) \n",
    "    \"\"\"\n",
    "\n",
    "    threshold = 1e-7\n",
    "    bm       = sol.y[:N, -1]\n",
    "    feasible = np.where(bm > threshold)[0]  \n",
    "\n",
    "    J_red  = J_micrm[:N, :N]   # True consumer‐block\n",
    "    J_red_sub = J_red[np.ix_(feasible, feasible)] # picks out only feasible ones \n",
    "    J_glv_red = J_glv[:N, :N]  # Your GLV consumer‐block\n",
    "    ΔJ     = J_red_sub - J_glv_red\n",
    "    normΔJ = np.linalg.norm(ΔJ, ord='fro')   # Frobenius norm of the difference\n",
    "    eigvals, eigvecs = np.linalg.eig(J_red)\n",
    "    V               = eigvecs\n",
    "    condV           = np.linalg.norm(V, 2) * np.linalg.norm(np.linalg.inv(V), 2)\n",
    "    BF_bound = condV * normΔJ\n",
    "\n",
    "         \n",
    "    ##### store results as a dictionary ##### \n",
    "\n",
    "    results.append(dict(T=T, \n",
    "                        sol=sol, \n",
    "                        sol_lv=sol_lv, \n",
    "                        ErrEqAb=ErrEqAb, \n",
    "                        overlap=overlap,\n",
    "                        ErrTraj=Err_traj,\n",
    "                        jaccard=jaccard,\n",
    "                        sh_LV=sh_LV,\n",
    "                        sh_Mi=sh_Mi,\n",
    "                        bray_curtis=bc,\n",
    "                        stab_glv=stab_glv,\n",
    "                        stab_mic=stab_mic,\n",
    "                        react_glv=react_glv,\n",
    "                        react_mic=react_mic,\n",
    "                        tau_C=tau_C,\n",
    "                        tau_R=tau_R,\n",
    "                        epsilon=epsilon,\n",
    "                        t_eq=t_eq,\n",
    "                        hessian_norm=hess_norm,\n",
    "                        nnorm=nnorm,\n",
    "                        normΔJ=normΔJ,\n",
    "                        condV=condV,\n",
    "                        BF_bound=BF_bound\n",
    "                        ))\n",
    "\n",
    "# analyse results for equilibrium abundance\n",
    "\n",
    "# extract values for plotting \n",
    "temps_C = temp_vals - 273.15 # Convert temperature array from K to °C\n",
    "errs     = [r['ErrEqAb'] for r in results]\n",
    "overlaps = [r['overlap']  for r in results]\n",
    "errtraj = [r['ErrTraj']  for r in results]\n",
    "jaccards = [r['jaccard'] for r in results]\n",
    "sh_lvs   = [r['sh_LV']   for r in results]\n",
    "sh_mis   = [r['sh_Mi']   for r in results]\n",
    "bcs = [r['bray_curtis']   for r in results]\n",
    "stabs_glv  = [r['stab_glv']  for r in results]\n",
    "stabs_mic  = [r['stab_mic']  for r in results]\n",
    "reacts_glv = [r['react_glv'] for r in results]\n",
    "reacts_mic = [r['react_mic'] for r in results]\n",
    "abs_diff_stab  = np.abs(np.array(stabs_glv ) - np.array(stabs_mic )) # absolute differences \n",
    "abs_diff_react = np.abs(np.array(reacts_glv) - np.array(reacts_mic)) # absolute differences \n",
    "taus_C      = [r['tau_C']    for r in results]\n",
    "taus_R      = [r['tau_R']    for r in results]\n",
    "epsilons    = [r['epsilon']  for r in results]\n",
    "t_eqs     = [r['t_eq']    for r in results]\n",
    "hessians   = [r['hessian_norm'] for r in results]\n",
    "nnorms        = [r['nnorm']         for r in results]\n",
    "normΔJ = [r['normΔJ'] for r in results]\n",
    "condVs       = [r['condV']       for r in results]\n",
    "BF_bounds     = [r['BF_bound']     for r in results]\n",
    "\n",
    "######################################### PLOTTING #############################################\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot abundance deviation at equilibrium \n",
    "plt.figure()\n",
    "plt.plot(temps_C, errs)\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Mean Log-Ratio Error (GLV vs MiCRM)\")\n",
    "plt.title(\"Equilibrium Abundance Error vs Temperature\")\n",
    "plt.axhline(0, linestyle='--')   # horizontal zero line\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot number of species overlap for GLV/MiCRM at equilibrium (accuracy in terms of diversity predictions)\n",
    "plt.figure()\n",
    "plt.plot(temps_C, overlaps, marker='s', label='Overlap Count')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Number of Shared Survivors\")\n",
    "plt.title(\"Shared Species Count vs Temperature\")\n",
    "plt.ylim(-0.5, N + 0.5)  # N is total species, e.g. 7\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot trajectory deviation \n",
    "plt.figure()\n",
    "plt.plot(temps_C, errtraj)\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Trajectory Deviation (GLV vs MiCRM)\")\n",
    "plt.title(\"Trajectory Error vs Temperature\")\n",
    "plt.axhline(0, linestyle='--')   # horizontal zero line\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs Jaccard\n",
    "plt.figure()\n",
    "plt.plot(temps_C, jaccards, marker='o')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Jaccard Index (GLV vs MiCRM)\")\n",
    "plt.title(\"Jaccard vs Temperature\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs Shannon diversity (two lines)\n",
    "plt.figure()\n",
    "plt.plot(temps_C, sh_lvs, marker='s', label=\"GLV Shannon\")\n",
    "plt.plot(temps_C, sh_mis, marker='^', label=\"MiCRM Shannon\")\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Shannon Diversity H'\")\n",
    "plt.title(\"Shannon Diversity vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bray-Curtis (for community composition - incorporating both diversity + abundance)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(temps_C, bcs, marker='o')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Bray–Curtis Dissimilarity\")\n",
    "plt.title(\"Bray–Curtis Dissimilarity vs Temperature\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs leading Jacobian eigenvalue\n",
    "plt.figure()\n",
    "plt.plot(temps_C, stabs_glv, marker='o', label='GLV')\n",
    "plt.plot(temps_C, stabs_mic, marker='^', label='MiCRM')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Leading Jacobian Eigenvalue\")\n",
    "plt.title(\"Stability (Jacobian) vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs |Δ leading Jacobian eigenvalue|    (absolute difference) \n",
    "plt.figure()\n",
    "plt.plot(temps_C, abs_diff_stab, marker='o', label='|GLV – MiCRM|')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Absolute Δ Jacobian Eigenvalue\")\n",
    "plt.title(\"Absolute Stability Error vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs leading Hermitian‐part eigenvalue\n",
    "plt.figure()\n",
    "plt.plot(temps_C, reacts_glv, marker='o', label='GLV')\n",
    "plt.plot(temps_C, reacts_mic, marker='^', label='MiCRM')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Leading Hermitian Eigenvalue\")\n",
    "plt.title(\"Reactivity (Hermitian) vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs |Δ leading Hermitian eigenvalue|   (absolute difference)\n",
    "plt.figure()\n",
    "plt.plot(temps_C, abs_diff_react, marker='o', label='|GLV – MiCRM|')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Absolute Δ Hermitian Eigenvalue\")\n",
    "plt.title(\"Absolute Reactivity Error vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs consumer & resource timescales\n",
    "plt.figure()\n",
    "plt.plot(temps_C, taus_C, marker='o', label='τ_C (fastest consumer)')\n",
    "plt.plot(temps_C, taus_R, marker='^', label='τ_R (slowest resource)')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Return Time (τ)\")\n",
    "plt.title(\"MiCRM Return Times vs Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temperature vs timescale‐separation ε = τ_C / τ_R\n",
    "plt.figure()\n",
    "plt.plot(temps_C, epsilons, marker='o')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Timescale Separation ε\")\n",
    "plt.title(\"Consumer/Resource Timescale Separation vs Temperature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# timescale separation, log10(epsilon / t_eq) vs Temperature\n",
    "\n",
    "ratio = np.log10(np.array(epsilons) / np.array(t_eqs))\n",
    "plt.figure()\n",
    "plt.plot(temps_C, ratio, marker='o')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(r\"$\\log_{10}(\\varepsilon / t_{eq})$\")\n",
    "plt.title(\"Log10 of Timescale Separation Relative to Time-to-Equilibrium\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Investigating what is causing differences in reactivity / stability \n",
    "\"\"\"\n",
    "\n",
    "# Curvature vs Temperature\n",
    "plt.figure()\n",
    "plt.plot(temps_C, hessians, marker='o')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Hessian Norm\")\n",
    "plt.title(\"Nonlinear Curvature vs Temperature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reactivity‐error vs Curvature\n",
    "plt.figure()\n",
    "plt.scatter(hessians, abs_diff_react)\n",
    "plt.xlabel(\"Hessian Norm\")\n",
    "plt.ylabel(\"Absolute Reactivity Error (|Δμ|)\")\n",
    "plt.title(\"Curvature drives Reactivity Error\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# non-normality vs reactivity error\n",
    "plt.figure()\n",
    "plt.scatter(nnorms, abs_diff_react)\n",
    "plt.xlabel(\"Non-normality ‖J Jᵀ – Jᵀ J‖₍F₎\")\n",
    "plt.ylabel(\"Absolute Reactivity Error |Δμ|\")\n",
    "plt.title(\"Non-Normality Drives Reactivity Error\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# non-normality vs temperature \n",
    "plt.figure()\n",
    "plt.plot(temps_C, nnorms, marker='o')\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Non-normality\")\n",
    "plt.title(\"Non-normality vs Temperature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# bauer fike (why stability changes with temp)\n",
    "plt.figure()\n",
    "plt.plot(temps_C, abs_diff_stab, label='Observed |Δλ|')\n",
    "plt.plot(temps_C, BF_bounds,   label='BF bound')\n",
    "plt.legend()\n",
    "plt.title(\"BF Bound vs Stability Error\")\n",
    "plt.xlabel(\"Temperature (°C)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
